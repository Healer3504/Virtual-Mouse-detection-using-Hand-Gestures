# Virtual-Mouse-detection-using-Hand-Gestures
The Virtual Mouse Detection project aims to develop a system that allows users to control the mouse pointer through hand gestures using computer vision techniques. This project utilizes a webcam to track hand movements and detect specific gestures to simulate mouse actions such as moving the cursor, leftclicking, right-clicking, double-clicking.
1. Introduction
1.1 Project Overview
The Virtual Mouse Detection project aims to develop a system that allows users
to control the mouse pointer through hand gestures using computer vision
techniques. This project utilizes a webcam to track hand movements and detect
specific gestures to simulate mouse actions such as moving the cursor, leftclicking, right-clicking, double-clicking.
1.2 Objective
The main objective is to implement a computer vision-based virtual mouse
system using Python, OpenCV, Mediapipe, and PyAutoGUI that can:
● Track hand gestures.
● Translate these gestures into mouse actions.
● Perform actions like left-click, right-click, double-click.
2. Tools and Technologies
2.1 Programming Language:
● Python: Python was used for its rich ecosystem of libraries in computer
vision, hand tracking, and GUI automation.
2.2 Libraries:
● OpenCV: A popular computer vision library used for capturing video and
processing images.
● Mediapipe: A cross-platform framework used for building perception
pipelines, specifically the hand tracking model in this project.
● PyAutoGUI: A library used to automate the mouse movements.
● Pynput: Used for controlling and monitoring the mouse actions.
● NumPy: For mathematical operations on arrays, especially for computing
distances and angles between hand landmarks.
2.3 Tools:
● VS Code: Used as the Integrated Development Environment (IDE).
● Webcam: Required for capturing hand movements.
